"""
M√≥dulo de Ingest√£o de Dados para FAISS
Carrega documentos (compliance e emails) em √≠ndices separados
"""
import os
from typing import List
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente
load_dotenv()

class DataIngestion:
    """Classe para gerenciar a ingest√£o de dados no FAISS"""
    
    def __init__(self, persist_directory: str = "./faiss_index"):
        """
        Inicializa o sistema de ingest√£o
        
        Args:
            persist_directory: Diret√≥rio onde os √≠ndices FAISS ser√£o salvos
        """
        self.persist_directory = persist_directory
        
        # Inicializa o modelo de embeddings local (sem necessidade de API key)
        print("üîß Carregando modelo de embeddings local...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("‚úÖ Modelo de embeddings carregado!")
    
    def ingest_compliance_policy(self, file_path: str) -> FAISS:
        """
        Ingere a pol√≠tica de compliance no FAISS
        
        Args:
            file_path: Caminho para o arquivo politica_compliance.txt
            
        Returns:
            Inst√¢ncia do FAISS vectorstore
        """
        print(f"üìÑ Carregando pol√≠tica de compliance de {file_path}...")
        
        # Carrega o documento
        loader = TextLoader(file_path, encoding='utf-8')
        documents = loader.load()
        
        # Divide em chunks menores para precis√£o nas regras
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        chunks = text_splitter.split_documents(documents)
        
        print(f"‚úÇÔ∏è  Documento dividido em {len(chunks)} chunks")
        
        # Cria o √≠ndice FAISS
        vectorstore = FAISS.from_documents(
            documents=chunks,
            embedding=self.embeddings
        )
        
        # Salva o √≠ndice
        compliance_path = os.path.join(self.persist_directory, "compliance")
        vectorstore.save_local(compliance_path)
        
        print(f"‚úÖ √çndice 'compliance' criado com sucesso!")
        return vectorstore
    
    def ingest_emails(self, file_path: str) -> FAISS:
        """
        Ingere os emails no FAISS
        
        Args:
            file_path: Caminho para o arquivo emails.txt
            
        Returns:
            Inst√¢ncia do FAISS vectorstore
        """
        print(f"üìß Carregando emails de {file_path}...")
        
        # Carrega o documento
        loader = TextLoader(file_path, encoding='utf-8')
        documents = loader.load()
        
        # Divide em chunks maiores para manter contexto das conversas
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n-------------------------------------------------------------------------------\n", "\n\n", "\n", " "]
        )
        chunks = text_splitter.split_documents(documents)
        
        print(f"‚úÇÔ∏è  Documento dividido em {len(chunks)} chunks")
        
        # Cria o √≠ndice FAISS
        vectorstore = FAISS.from_documents(
            documents=chunks,
            embedding=self.embeddings
        )
        
        # Salva o √≠ndice
        emails_path = os.path.join(self.persist_directory, "emails")
        vectorstore.save_local(emails_path)
        
        print(f"‚úÖ √çndice 'emails' criado com sucesso!")
        return vectorstore
    
    def check_if_ingested(self) -> bool:
        """
        Verifica se os dados j√° foram ingeridos
        
        Returns:
            True se j√° existem √≠ndices, False caso contr√°rio
        """
        if not os.path.exists(self.persist_directory):
            return False
        
        compliance_path = os.path.join(self.persist_directory, "compliance")
        return os.path.exists(compliance_path)


def main():
    """Fun√ß√£o principal para executar a ingest√£o"""
    print("üöÄ Iniciando processo de ingest√£o de dados...\n")
    
    # Inicializa o sistema de ingest√£o
    ingestion = DataIngestion()
    
    # Verifica se j√° foi ingerido
    if ingestion.check_if_ingested():
        print("‚ÑπÔ∏è  Dados j√° foram ingeridos anteriormente.")
        print("   Para reingerir, delete a pasta 'faiss_index' e execute novamente.")
        return
    
    # Define os caminhos dos arquivos
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    compliance_path = os.path.join(base_dir, "data", "politica_compliance.txt")
    emails_path = os.path.join(base_dir, "data", "emails.txt")
    
    # Verifica se os arquivos existem
    if not os.path.exists(compliance_path):
        raise FileNotFoundError(f"Arquivo n√£o encontrado: {compliance_path}")
    if not os.path.exists(emails_path):
        raise FileNotFoundError(f"Arquivo n√£o encontrado: {emails_path}")
    
    # Ingere os documentos
    ingestion.ingest_compliance_policy(compliance_path)
    print()
    ingestion.ingest_emails(emails_path)
    
    print("\n‚ú® Processo de ingest√£o conclu√≠do com sucesso!")
    print("   Os dados est√£o prontos para serem consultados pelo agente.")


if __name__ == "__main__":
    main()
